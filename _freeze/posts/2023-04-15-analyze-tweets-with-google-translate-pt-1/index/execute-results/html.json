{
  "hash": "5ca2f077b6ad78b608671173df6bd30b",
  "result": {
    "markdown": "---\ntitle: \"Sentiment Analysis Using Google Translate (Pt. 1)\"\nauthor: \"Art Steinmetz\"\ndate: \"2023-04-15\"\nformat: html\neditor: visual\nbibliography: references.bib\nexecute: \n  freeze: true\n---\n\n\nCan an English speaker use Google Cloud Translate to conduct experiments with natural language processing? Let's fund out.\n\n## Inspired by TidyTuesday\n\nSome of the the R data science community participate in a weekly challenge called \"Tidy Tuesday,\" where an interesting data set is presented for analysis but mostly visualization. There are some tremendous examples of beautiful work posted on [Twitter](twitter.com) with the hashtag #tidytuesday.\n\n## African Tweets and Sentiment\n\nRecently, the weekly dataset was a collection of over 100,000 tweets, apparently from 2022, in 14 African languages, with sentiment labels. The paper describing the set and methods is [here](https://arxiv.org/pdf/2302.08956.pdf) [@muhammad-etal-2023-semeval]. The TidyTuesday project and raw data are [here](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-02-28/readme.md). This is quite a diverse data set including many tweets in English, tweets in languages which, like English, use the Latin character set and tweets in other character sets, including Arabic.\n\nI saw this as an avenue to ask a couple interesting questions.\n\n1.  Can we apply sentiment analysis techniques to a translated version of this dataset? How good is Google Translate, anyway?\n2.  Over the past year there has been much talk about the differences in attitudes of the \"global north\" vs. the \"global south.\" Does this data set reveal anything about that?\n\nI also saw an opportunity to sharpen my skills in a couple areas, using the Google API for batch translation and using RStudio's Tidytext and Tidymodels toolsets.\n\nI split these explorations into four snack-able posts.\n\n1.  In this post we show how to use Google Cloud Translate to batch translate the entire data set.\n2.  Here we use the tidytext framework to do sentiment analysis with word valences.\n3.  Next, we'll compare machine learning approaches in the tidymodels framework to do sentiment analysis on both the native and translated tweets.\n4.  Finally, let's use the already assigned sentiment tags to explore African attitudes to the \"global north.\"\n\n::: callout-caution\n## Disclaimer\n\nThe usual caveats apply. I am not a social scientist. I am a hobbyist. This is an exercise in R coding so I make no claim that my conclusions about any of this data are valid.\n:::\n\n## Get the Data\n\nHere are the packages we'll need for this project.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(googleLanguageR)\n  library(future)\n  library(furrr)\n  library(rvest)\n})\n```\n:::\n\n\nThe TidyTuesday github repo has the Afrisenti dataset with all the languages combined. Let's load it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nafrisenti <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-28/afrisenti.csv',\n                             show_col_types = FALSE)\n\nafrisenti\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 111,720 × 4\n   language_iso_code tweet                                         label inten…¹\n   <chr>             <chr>                                         <chr> <chr>  \n 1 amh               አማራ ክልል ፈልቶበታል ልኩን ማስገባት ነው!!! ሙስሊሞችን ጠልቶ 85… nega… dev    \n 2 amh               ሰውን አንገት በሚያስደፋ መልኩ ዝም ብሎ ሙድ መያዝ....ስልህ ያ ሰው… nega… dev    \n 3 amh               የቤት ውስጥ ጥቃት – ያለሰሚ – ያለተመልካች                  nega… dev    \n 4 amh               Ethiopia ወያኔን ለመጣል ምን ድርሻ ነበራችሁ ? ከወደቀ በኋላ ጉ… nega… dev    \n 5 amh               ኦሮሞ ምንም ቢማር ከብት ነዉ አያስተዉልም ጥንብ ዘረኛ ናቸዉ        nega… dev    \n 6 amh               ቲሽ ጨለምተኛ ዱቄት 97 ላይ ቆመሃል እንዴ ጊዜው ነጉዷል 2012 ነው… nega… dev    \n 7 amh               በምዕራብ ኦሮሚያ በሚገኙ በሁለቱ የወለጋ ዞኖች (ምስራቅ ወለጋና ሆሮ … nega… dev    \n 8 amh               ያየሰው ሺመልስ ላይ የደረሰው ነገር ያሳዝናል። በቃል ኣላምረውም ላይም… nega… dev    \n 9 amh               ያልተረጋጋች ሀገር ምርጫ አያስፈልጋትም                      nega… dev    \n10 amh               ደደቡ እና አረፋው የኢትዮጵያው ጠ/ሚ አብዪ ከኤርትራው ኣያቶላህ ኢሰያ… nega… dev    \n# … with 111,710 more rows, and abbreviated variable name ¹​intended_use\n```\n:::\n:::\n\n\n## Translate the Tweets\n\nTo use Google translate in batch mode we'll need an API key. I don't understand Google. For some of their services, like Maps, a single API key is needed. Instead, for Translate, we need a JSON file with the key. Once you get the key, store the file name in your `.Renviron` file with the key name \"GL_AUTH\" then the googlelanguageR package will automatically authenticate when it loads.\n\n::: callout-note\nGetting the Google Language API key is a complicated procedure and I won't detail it here but you can find complete instructions in the [googlelanguageR package introduction](https://cran.r-project.org/web/packages/googleLanguageR/vignettes/setup.html).\n:::\n\nOnce once your key is created you can start translating with R. *This isn't free.* Translating over 100,000 tweets cost me about US\\$15. A couple bucks was wasted because I submitted all the tweets including those in English. You might choose to filter English tweets out first. If you just want to work with the same data set you can download my translations (see below) for FREE.\n\nI first tried shooting the whole data set into the translation routine but Google protested that I was sending too much. I divided the set into batches of 100 tweets at a time which fixed the problem.\n\nWe can dramatically speed things up using the `furrr` and `future` packages to allow parallel processing using just three lines of code. `furrr` adapts the `purrr::map()` family of functions to allow parallel execution. Very simple. Amazing!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfuture::plan(multicore) # will use all available cores\nbatch_size = min(100, nrow(afrisenti))\nafrisenti_translated <- \n  seq(0, nrow(afrisenti) - batch_size,\n      by = batch_size) |>\n  furrr::future_map_dfr(\\(x) {\n    gl_translate(afrisenti$tweet[(x + 1):(x + batch_size)])\n    }, .progress = TRUE)\nfuture::plan(sequential) # back to normal\n```\n:::\n\n\nIt's worth looking over the code above because it packs a lot of power in few lines and, to me, shows how cool R is. Basically, we identify the batches of rows from the data set we want to ship out to Google and translate them in as many parallel streams as our hardware allows.\n\nLet's clean up the data a little.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# merge with source data and clean up a little\nafrisenti_translated <- afrisenti_translated |> \n  na.omit() |> \n  select(-text) |> \n  bind_cols(afrisenti) |> \n  rowid_to_column(var = \"tweet_num\") |> \n  mutate(tweet_num = as.numeric(tweet_num))\n  mutate(intended_use = as_factor(intended_use)) |>\n  mutate(detectedSourceLanguage = as_factor(detectedSourceLanguage)) |>\n  mutate(language_iso_code = as_factor(language_iso_code)) |>\n  mutate(label = as.factor(label))\n```\n:::\n\n\nWhile it's not strictly necessary, I wanted to see the long names for the languages, rather than just 2-character ISO codes. Using Wikipedia I created a file that we can use for reference. The `rvest` package makes turning an HTML table into a data frame easy. At the same time, let's make sure the language labels from the data set are consistent with the Google language labels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get languages from wikipedia\n# take the second table on the page\niso_lang <- html_table(read_html(\"https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes#External_links\"))[[2]]\n\n# since Wikipedia is subject to frequent change, if the entry doesn't work\n# you can get the file here\n# iso_lang <- readr::read_csv('https://raw.githubusercontent.com/apsteinmetz/tidytuesday/master/2023-02-28_african_language/data/iso_lang.csv',\n#                              show_col_types = FALSE)\n\niso_lang <- iso_lang %>% \n  rename(assigned_language = `639-2/T`,\n         detected_language = `639-1`,\n         language = `ISO language name`) %>% \n  select(1:3)\n\n# clean up langauge names\nafrisenti_translated <- afrisenti_translated %>% \n  mutate(language_iso_code = str_replace_all(language_iso_code,\"pt-MZ\",\"por\")) %>% \n  mutate(language_iso_code = str_replace_all(language_iso_code,\"ary\",\"ara\")) %>% \n  mutate(language_iso_code = str_replace_all(language_iso_code,\"arq\",\"ara\")) %>% \n  mutate(language_iso_code = str_replace_all(language_iso_code,\"pcm\",\"eng\")) %>% \n  rename(assigned_language = language_iso_code,\n         detected_language = detectedSourceLanguage) %>% \n  left_join(select(iso_lang,-assigned_language)) %>% \n  rename(detected_long = language) %>% \n  left_join(select(iso_lang,-detected_language)) %>% \n  rename(assigned_long = language)\n  \n# save it for later use\nsave(afrisenti_translated,file=\"data/afrisenti_translated.rdata\")\n```\n:::\n\n\n## Save Some Money\n\nThat done, YOU don't want to pay \\$15 and you don't have to. Let's download the translated Afrisenti data set from my repo instead.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nafrisenti_translated <- readr::read_csv('https://raw.githubusercontent.com/apsteinmetz/tidytuesday/master/2023-02-28_african_language/data/afrisenti_translated.csv',\n                                        show_col_types = FALSE)\nafrisenti_translated\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 111,720 × 9\n   tweet_num translatedText  detec…¹ assig…² tweet label inten…³ detec…⁴ assig…⁵\n       <dbl> <chr>           <chr>   <chr>   <chr> <chr> <chr>   <chr>   <chr>  \n 1         1 Amhara region … am      amh     አማራ … nega… dev     Amharic Amharic\n 2         2 Having a mood … am      amh     ሰውን … nega… dev     Amharic Amharic\n 3         3 Domestic viole… am      amh     የቤት … nega… dev     Amharic Amharic\n 4         4 Ethiopia, what… am      amh     Ethi… nega… dev     Amharic Amharic\n 5         5 No matter how … am      amh     ኦሮሞ … nega… dev     Amharic Amharic\n 6         6 Tish, dark pow… am      amh     ቲሽ ጨ… nega… dev     Amharic Amharic\n 7         7 Local resident… am      amh     በምዕራ… nega… dev     Amharic Amharic\n 8         8 What happened … am      amh     ያየሰው… nega… dev     Amharic Amharic\n 9         9 An unstable co… am      amh     ያልተረ… nega… dev     Amharic Amharic\n10        10 The idiot and … am      amh     ደደቡ … nega… dev     Amharic Amharic\n# … with 111,710 more rows, and abbreviated variable names ¹​detected_language,\n#   ²​assigned_language, ³​intended_use, ⁴​detected_long, ⁵​assigned_long\n```\n:::\n:::\n\n\n## Do a Reality Check\n\nNow that the hard work is done let's do some preliminary checks, Let's see if the language that Google detects agrees with the assigned language in the data set. First we convert the language long names to factors and see how many levels there are. These are the 13 assigned languages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nafrisenti_translated <- afrisenti_translated |> \n  mutate(across(contains(\"long\"),\\(x) as.factor(x)))\n\nlevels(afrisenti_translated$assigned_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Amharic\"     \"Arabic\"      \"English\"     \"Hausa\"       \"Igbo\"       \n [6] \"Kinyarwanda\" \"Oromo\"       \"Portuguese\"  \"Swahili\"     \"Tigrinya\"   \n[11] \"Tsonga\"      \"Twi\"         \"Yoruba\"     \n```\n:::\n:::\n\n\nHere are the languages that Google detects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(afrisenti_translated$detected_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Afrikaans\"                     \"Akan\"                         \n [3] \"Amharic\"                       \"Arabic\"                       \n [5] \"Aymara\"                        \"Bambara\"                      \n [7] \"Basque\"                        \"Bengali\"                      \n [9] \"Bosnian\"                       \"Bulgarian\"                    \n[11] \"Catalan, Valencian\"            \"Chichewa, Chewa, Nyanja\"      \n[13] \"Chinese\"                       \"Corsican\"                     \n[15] \"Croatian\"                      \"Czech\"                        \n[17] \"Danish\"                        \"Dutch, Flemish\"               \n[19] \"English\"                       \"Esperanto\"                    \n[21] \"Estonian\"                      \"Ewe\"                          \n[23] \"Finnish\"                       \"French\"                       \n[25] \"Gaelic, Scottish Gaelic\"       \"Galician\"                     \n[27] \"Ganda\"                         \"German\"                       \n[29] \"Greek, Modern (1453–)\"         \"Guarani\"                      \n[31] \"Gujarati\"                      \"Haitian, Haitian Creole\"      \n[33] \"Hausa\"                         \"Hindi\"                        \n[35] \"Hungarian\"                     \"Igbo\"                         \n[37] \"Indonesian\"                    \"Irish\"                        \n[39] \"Italian\"                       \"Japanese\"                     \n[41] \"Javanese\"                      \"Kannada\"                      \n[43] \"Kinyarwanda\"                   \"Korean\"                       \n[45] \"Kurdish\"                       \"Latin\"                        \n[47] \"Latvian\"                       \"Lingala\"                      \n[49] \"Luxembourgish, Letzeburgesch\"  \"Malagasy\"                     \n[51] \"Malay\"                         \"Malayalam\"                    \n[53] \"Maltese\"                       \"Maori\"                        \n[55] \"Marathi\"                       \"Norwegian\"                    \n[57] \"Oromo\"                         \"Pashto, Pushto\"               \n[59] \"Persian\"                       \"Polish\"                       \n[61] \"Portuguese\"                    \"Quechua\"                      \n[63] \"Romanian, Moldavian, Moldovan\" \"Russian\"                      \n[65] \"Samoan\"                        \"Shona\"                        \n[67] \"Sindhi\"                        \"Slovak\"                       \n[69] \"Slovenian\"                     \"Somali\"                       \n[71] \"Southern Sotho\"                \"Spanish, Castilian\"           \n[73] \"Sundanese\"                     \"Swahili\"                      \n[75] \"Swedish\"                       \"Tamil\"                        \n[77] \"Telugu\"                        \"Tigrinya\"                     \n[79] \"Tsonga\"                        \"Turkish\"                      \n[81] \"Turkmen\"                       \"Ukrainian\"                    \n[83] \"Urdu\"                          \"Uzbek\"                        \n[85] \"Vietnamese\"                    \"Welsh\"                        \n[87] \"Western Frisian\"               \"Xhosa\"                        \n[89] \"Yoruba\"                        \"Zulu\"                         \n```\n:::\n:::\n\n\nUh, oh. 90 detected languages vs. 13 assigned languages. Is this a problem? What fraction of tweets are in languages not mentioned in the original set?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalt_count <- afrisenti_translated |> \n  filter(!(detected_long %in% levels(assigned_long))) |> \n  nrow()/nrow(afrisenti_translated)*100 \n\npaste0(round(alt_count,1),\"%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"6.9%\"\n```\n:::\n:::\n\n\nNot a big number. Let's collapse all but the top 15 languages into an \"other\" category.\n\nHow frequently does Google disagree with the assigned language?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nafrisenti_translated <- afrisenti_translated |> \n  mutate(detected_long = replace_na(as.character(detected_long,\"Unknown\"))) |> \n  mutate(detected_long = fct_lump_n(detected_long,15))\n\nxt <- xtabs(~afrisenti_translated$assigned_long +\n        afrisenti_translated$detected_long) |> \n  broom::tidy() |> \n  rename(assigned = 1,google = 2) |> \n  group_by(assigned) |> \n  mutate(Proportion = n/sum(n))\n   \nxt |>\n  ggplot(aes(assigned, google,fill=Proportion)) + geom_tile() +\n  scale_fill_gradient(low = \"#FFBF00\", high = \"#007000\") +\n  theme(\n    plot.background = element_rect(fill = \"#FDECCD\", color = NA),\n    legend.background = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(angle = 45,vjust = .7,hjust = .6), \n    panel.background = element_blank(),\n    panel.grid = element_blank()\n  ) +\n  labs(\n    title = \"African Languages Tweets\\nQ: Does Google Detect The Same Language?\",\n    subtitle = \"A: Almost Entirely\",\n    x = \"Afrisenti Assigned Language\",\n    y = \"Google Translate Detected Language\",\n    caption = \"source: Afrisenti Data Set\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe fact that disagreement about the tweet language is so rare gives us some confidence that we are on the right track.\n\nThen look at the first row.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(cat(\nafrisenti_translated$tweet[1],\"\\n\",\nafrisenti_translated$translatedText[1],\"\\n\",\nafrisenti_translated$label[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nአማራ ክልል ፈልቶበታል ልኩን ማስገባት ነው!!! ሙስሊሞችን ጠልቶ 85% ሙስሊሞች በሚኖርባት ኦሮምያ ጋር ግንኙነትን አትሰበው !!! \n Amhara region needs moderation!!! He hates Muslims and does not think of relations with Oromia, where 85% of Muslims live!!! \n negativeNULL\n```\n:::\n:::\n\n\nA quick glance at the translation shows obviously negative sentiment. We are off to a promising start. In the next post we'll use the tidytext framework to measure the net balance of sentiment for each tweet.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}